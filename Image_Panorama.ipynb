{"cells":[{"cell_type":"markdown","metadata":{"id":"o5-RnjjbKzhz"},"source":["This code is given in https://github.com/allan-tulane/CMPS4661-6663/blob/main/Image_Stitching.ipynb\n","Most of them are implemented using existing libraries\n","\n","The below one is simplified to panorama over multiple images.\n","There are 5 steps listed in the program including\n","- Step 1: read two images and resize to the same size\n","- Step 2: detect the features and keypoints from SIFT\n","- Step 3: get the valid matched points out of all\n","- Step 4: Call cv2.findHomography to calculate the 3x3 H matrix\n","- Step 5: to get perspective of image using computed homography\n","\n","## To Do\n","**Task 1**: This aims to reimplement Step 4 instead of using *cv2.findHomography*, which calcutlates the H matrix (3x3) using RANSAC given all matched pairs from image A and image B. You will implement two ways to calculate H.\n","\n","- First, check the Concept *The direct linear transform (DLT)*. Please directly implement DLT (Page 50 in the slides) using all pairs to calculate H, which serves as the baseline.\n","\n","- Second, check *Estimating homography using RANSAC* to recalculate H. When we count inliers, we can use Squared SUM Error (SSE) to determine each line. That is, given a pair (p, q), we can calculate the SSE of the converted Hp, and q. If their SSE is smaller than a threshold, that is an inlier. The threshold is manually set. You can try different values.\n","\n","Note that you first use the given two images, then try to use the three images in folder **Sample**. When we have multiple images, we should stitch every two images sequentially.\n","\n","**Task 2**: There are several parameters like lowe_ratio in def All_validmatches(AllMatches, lowe_ratio), and how many iterations in RANSAC for H. Please try different values to see the difference of output.\n","\n","**Task 3**: The given code does a hard seem, which can not given a smooth result when two images have different illumination, exposures. Can you explore to achieve better results? Please implement the methods we discuss in class like **choose seaming** and **blending** like **alpha blending**, **multi-band blending as Laplacian Pyramid**. Please use the two pairs of images in folder of **Sample2**.\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1728759129079,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"},"user_tz":300},"id":"NgWT05QRK5Er","outputId":"9c887794-1661-493a-c55b-e02142c1c225"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["## to access the google drive with the google account\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":785,"status":"ok","timestamp":1728759130474,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"},"user_tz":300},"id":"Q8tf9_CwKzh1"},"outputs":[],"source":["import numpy as np\n","import imutils\n","import cv2\n","from matplotlib import pyplot as plt\n","\n","def Detect_Feature_And_KeyPoints(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # detect and extract features from the image\n","    descriptors = cv2.xfeatures2d.SIFT_create()\n","    (Keypoints, features) = descriptors.detectAndCompute(image, None)\n","\n","    Keypoints = np.float32([i.pt for i in Keypoints])\n","    return (Keypoints, features)\n","\n","def get_Allpossible_Match(featuresA,featuresB):\n","\n","    # compute the all matches using euclidean distance and opencv provide\n","    #DescriptorMatcher_create() function for that\n","    match_instance = cv2.DescriptorMatcher_create(\"BruteForce\")\n","    All_Matches = match_instance.knnMatch(featuresA, featuresB, 2)\n","\n","    return All_Matches\n","\n","def All_validmatches(AllMatches, lowe_ratio):\n","    #to get all valid matches according to lowe concept..\n","    valid_matches = []\n","\n","    for val in AllMatches:\n","        if len(val) == 2 and val[0].distance < val[1].distance * lowe_ratio:\n","            valid_matches.append((val[0].trainIdx, val[0].queryIdx))\n","\n","    return valid_matches\n","\n","def getwarp_perspective(imageA,imageB,Homography):\n","    ## given two images and H matrix to generate the panaroma\n","    val = imageA.shape[1] + imageB.shape[1]\n","    result_image = cv2.warpPerspective(imageA, Homography, (val , imageA.shape[0]))\n","\n","    return result_image\n","\n","def draw_Matches(imageA, imageB, KeypointsA, KeypointsB, matches, status):\n","\n","    (hA,wA) = imageA.shape[:2]\n","    (hB, wB) = imageB.shape[:2]\n","    vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n","    vis[0:hA, 0:wA] = imageA\n","    vis[0:hB, wA:] = imageB\n","\n","    # loop over the matches\n","    for ((trainIdx, queryIdx), s) in zip(matches, status):\n","        if s == 1:\n","            ptA = (int(KeypointsA[queryIdx][0]), int(KeypointsA[queryIdx][1]))\n","            ptB = (int(KeypointsB[trainIdx][0]) + wA, int(KeypointsB[trainIdx][1]))\n","            cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n","\n","\n","def construct_A_matrix(valid_matches, points_A, points_B):\n","    A = []\n","    for match in valid_matches:\n","        trainIdx = match[0]\n","        queryIdx = match[1]\n","        x, y = points_A[queryIdx]\n","        x_prime, y_prime = points_B[trainIdx]\n","        row1 = [x, y, 1, 0, 0, 0, -x_prime*x, -x_prime*y, -x_prime]\n","        row2 = [0, 0, 0, x, y, 1, -y_prime*x, -y_prime*y, -y_prime]\n","        A.append(row1)\n","        A.append(row2)\n","    A = np.array(A)\n","    return A\n","\n","def compute_homography(A):\n","    U, S, Vt = np.linalg.svd(A)\n","\n","    h = Vt[-1, :]\n","\n","    H = h.reshape(3, 3)\n","\n","    return H"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10731,"status":"ok","timestamp":1728759143460,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"},"user_tz":300},"id":"WjnhEpbgKzh3","outputId":"5a94dbf5-3e50-4ae7-e44f-1b1fc06e5f30"},"outputs":[{"output_type":"stream","name":"stdout","text":["524\n","6555\n","6555\n","[[ 1.11628768e-04  4.63076417e-04 -7.95241319e-01]\n"," [ 1.11217268e-04  3.49905691e-04 -6.06292547e-01]\n"," [ 8.97363700e-08  2.66756109e-07 -4.78844035e-04]]\n","[[ 6.48804151e-01  1.43937419e-02  1.21561229e+03]\n"," [-1.82943537e-01  9.15052799e-01  1.10793552e+02]\n"," [-1.40677264e-04  4.51871572e-06  1.00000000e+00]]\n","[[ 6.55182329e-01  1.45746339e-02  1.20345241e+03]\n"," [-1.71865885e-01  8.96484736e-01  1.18474818e+02]\n"," [-1.32295525e-04 -4.92913270e-06  1.00000000e+00]]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["# Step 1: read images and resize images\n","filename = ['q11.jpg', 'q22.jpg']\n","\n","images = []\n","img_path = '/content/drive/My Drive/Colab Notebooks/Assignment3/'\n","for i in range(len(filename)):\n","    ## read image and append\n","    images.append(cv2.imread(img_path+filename[i]))\n","    ## resize image to 2500x2500\n","    images[i] = cv2.resize(images[i], (2500, 2500))\n","\n","\n","\n","#Step 2: detect the features and keypoints from SIFT\n","(imageB, imageA) = images\n","(KeypointsA, featuresA) = Detect_Feature_And_KeyPoints(imageA)\n","(KeypointsB, featuresB) = Detect_Feature_And_KeyPoints(imageB)\n","\n","#Step 3: get the valid matched points\n","AllMatches = get_Allpossible_Match(featuresA, featuresB);\n","valid_matches = All_validmatches(AllMatches, lowe_ratio=0.75)\n","\n","#Step 4: Call cv2.findHomography\n","## the goal is to calculate the 3x3 H matrix\n","\n","print(len(valid_matches))\n","print(len(KeypointsA))\n","print(len(featuresA))\n","\n","\n","A=construct_A_matrix(valid_matches,KeypointsA,KeypointsB)\n","Hmatrix=compute_homography(A)\n","print(Hmatrix)\n","\n","\n","# construct the two sets of points\n","pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n","pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n","\n","(Homograpgy, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,4.0)\n","(Homograpgy2, status2) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,40.0)\n","print(Homograpgy)\n","print(Homograpgy2)\n","## Step 5: to get perspective of image using computed homography\n","result_image = getwarp_perspective(imageA, imageB, Homograpgy)\n","result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n","\n","draw_Matches(imageA, imageB, KeypointsA, KeypointsB, valid_matches, status)\n","\n","## Save the images\n","\n","cv2.imwrite(img_path+\"image_output.jpg\",result_image)\n","\n","##test\n","status2 = [1] * len(valid_matches)\n","result_image = getwarp_perspective(imageA, imageB, Hmatrix)\n","result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n","output_image = draw_Matches(imageA, imageB, KeypointsA, KeypointsB, valid_matches, status2)\n","cv2.imwrite(img_path+\"image_output2.jpg\",result_image)\n","\n","\n"]},{"cell_type":"markdown","source":["**Sample test a+b**"],"metadata":{"id":"32KKzOrb8IWQ"}},{"cell_type":"code","source":["# Step 1: read images and resize images\n","filenames = ['scene1_a.jpg', 'scene1_b.jpg']\n","\n","images = []\n","img_path = '/content/drive/My Drive/Colab Notebooks/Assignment3/Sample/'\n","\n","for filename in filenames:\n","\n","   img = cv2.imread(img_path + filename)\n","   height, width = img.shape[:2]\n","   new_height = 2000\n","   aspect_ratio = width / height\n","   new_width = int(new_height * aspect_ratio)\n","   img_resized = cv2.resize(img, (new_width, new_height))\n","   images.append(img_resized)\n","\n","\n","\n","\n","\n","#Step 2: detect the features and keypoints from SIFT\n","(imageB, imageA) = images\n","(KeypointsA, featuresA) = Detect_Feature_And_KeyPoints(imageA)\n","(KeypointsB, featuresB) = Detect_Feature_And_KeyPoints(imageB)\n","\n","#Step 3: get the valid matched points\n","AllMatches = get_Allpossible_Match(featuresA, featuresB);\n","valid_matches = All_validmatches(AllMatches, lowe_ratio=0.75)\n","\n","#Step 4: Call cv2.findHomography\n","## the goal is to calculate the 3x3 H matrix\n","\n","\n","\n","# construct the two sets of points\n","pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n","pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n","\n","(Homograpgy, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,5.0)\n","\n","## Step 5: to get perspective of image using computed homography\n","result_image = getwarp_perspective(imageA, imageB, Homograpgy)\n","\n","\n","\n","result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n","result_image.resize()\n","cv2.imwrite(img_path+\"ab.jpg\",result_image)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51o8TtZA8D0C","executionInfo":{"status":"ok","timestamp":1728759203706,"user_tz":300,"elapsed":59878,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"}},"outputId":"2d505adc-0ba6-4b50-efd9-30e42b7aaaa4"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**Sample test b+c**"],"metadata":{"id":"s4WZHlOF8kk5"}},{"cell_type":"code","source":["# Step 1: read images and resize images\n","filenames = ['scene1_b.jpg', 'scene1_c.jpg']\n","\n","images = []\n","img_path = '/content/drive/My Drive/Colab Notebooks/Assignment3/Sample/'\n","\n","for filename in filenames:\n","\n","   img = cv2.imread(img_path + filename)\n","   height, width = img.shape[:2]\n","   new_height = 2000\n","   aspect_ratio = width / height\n","   new_width = int(new_height * aspect_ratio)\n","   img_resized = cv2.resize(img, (new_width, new_height))\n","   images.append(img_resized)\n","\n","\n","\n","\n","\n","#Step 2: detect the features and keypoints from SIFT\n","(imageB, imageA) = images\n","(KeypointsA, featuresA) = Detect_Feature_And_KeyPoints(imageA)\n","(KeypointsB, featuresB) = Detect_Feature_And_KeyPoints(imageB)\n","\n","#Step 3: get the valid matched points\n","AllMatches = get_Allpossible_Match(featuresA, featuresB);\n","valid_matches = All_validmatches(AllMatches, lowe_ratio=0.75)\n","\n","#Step 4: Call cv2.findHomography\n","## the goal is to calculate the 3x3 H matrix\n","\n","\n","\n","# construct the two sets of points\n","pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n","pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n","\n","(Homograpgy, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,5.0)\n","\n","## Step 5: to get perspective of image using computed homography\n","result_image = getwarp_perspective(imageA, imageB, Homograpgy)\n","\n","\n","\n","result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n","result_image.resize()\n","cv2.imwrite(img_path+\"bc.jpg\",result_image)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFYueYjR8MUS","executionInfo":{"status":"ok","timestamp":1728757092049,"user_tz":300,"elapsed":52660,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"}},"outputId":"702ac84f-0265-4f7e-d19e-125765c5ba5b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**Task2**"],"metadata":{"id":"ctIYIGvM85sx"}},{"cell_type":"code","source":["filename = ['q11.jpg', 'q22.jpg']\n","\n","images = []\n","img_path = '/content/drive/My Drive/Colab Notebooks/Assignment3/'\n","for i in range(len(filename)):\n","    ## read image and append\n","    images.append(cv2.imread(img_path+filename[i]))\n","    ## resize image to 2500x2500\n","    images[i] = cv2.resize(images[i], (2500, 2500))\n","\n","\n","\n","#Step 2: detect the features and keypoints from SIFT\n","(imageB, imageA) = images\n","(KeypointsA, featuresA) = Detect_Feature_And_KeyPoints(imageA)\n","(KeypointsB, featuresB) = Detect_Feature_And_KeyPoints(imageB)\n","\n","#Step 3: get the valid matched points\n","AllMatches = get_Allpossible_Match(featuresA, featuresB);\n","valid_matches = All_validmatches(AllMatches, lowe_ratio=3)\n","\n","#Step 4: Call cv2.findHomography\n","## the goal is to calculate the 3x3 H matrix\n","\n","\n","# construct the two sets of points\n","pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n","pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n","\n","(Homograpgy, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,4.0)\n","\n","## Step 5: to get perspective of image using computed homography\n","result_image = getwarp_perspective(imageA, imageB, Homograpgy)\n","result_image[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n","\n","draw_Matches(imageA, imageB, KeypointsA, KeypointsB, valid_matches, status)\n","\n","## Save the images\n","\n","cv2.imwrite(img_path+\"image_outputtask2.jpg\",result_image)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKGYDuhd89BO","executionInfo":{"status":"ok","timestamp":1728757843338,"user_tz":300,"elapsed":6598,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"}},"outputId":"14bbf93a-cb0b-4970-fcc5-28f5208cadfb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**Task3**"],"metadata":{"id":"y-fhOil2AE3X"}},{"cell_type":"code","source":["import numpy as np\n","import imutils\n","import cv2\n","from matplotlib import pyplot as plt\n","\n","def Detect_Feature_And_KeyPoints(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # detect and extract features from the image\n","    descriptors = cv2.SIFT_create()\n","    (Keypoints, features) = descriptors.detectAndCompute(image, None)\n","\n","    Keypoints = np.float32([i.pt for i in Keypoints])\n","    return (Keypoints, features)\n","\n","def get_Allpossible_Match(featuresA,featuresB):\n","\n","    # compute the all matches using euclidean distance and opencv provide\n","    #DescriptorMatcher_create() function for that\n","    match_instance = cv2.DescriptorMatcher_create(\"BruteForce\")\n","    All_Matches = match_instance.knnMatch(featuresA, featuresB, 2)\n","\n","    return All_Matches\n","\n","def All_validmatches(AllMatches, lowe_ratio):\n","    #to get all valid matches according to lowe concept..\n","    valid_matches = []\n","\n","    for val in AllMatches:\n","        if len(val) == 2 and val[0].distance < val[1].distance * lowe_ratio:\n","            valid_matches.append((val[0].trainIdx, val[0].queryIdx))\n","\n","    return valid_matches\n","\n","def getwarp_perspective(imageA,imageB,Homography):\n","    ## given two images and H matrix to generate the panaroma\n","    val = imageA.shape[1] + imageB.shape[1]\n","    result_image = cv2.warpPerspective(imageA, Homography, (val , imageA.shape[0]))\n","\n","    return result_image\n","\n","def draw_Matches(imageA, imageB, KeypointsA, KeypointsB, matches, status):\n","\n","    (hA,wA) = imageA.shape[:2]\n","    (hB, wB) = imageB.shape[:2]\n","    vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n","    vis[0:hA, 0:wA] = imageA\n","    vis[0:hB, wA:] = imageB\n","\n","    # loop over the matches\n","    for ((trainIdx, queryIdx), s) in zip(matches, status):\n","        if s == 1:\n","            ptA = (int(KeypointsA[queryIdx][0]), int(KeypointsA[queryIdx][1]))\n","            ptB = (int(KeypointsB[trainIdx][0]) + wA, int(KeypointsB[trainIdx][1]))\n","            cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n","\n","\n","def construct_A_matrix(valid_matches, points_A, points_B):\n","    A = []\n","    for match in valid_matches:\n","        trainIdx = match[0]\n","        queryIdx = match[1]\n","        x, y = points_A[queryIdx]\n","        x_prime, y_prime = points_B[trainIdx]\n","        row1 = [x, y, 1, 0, 0, 0, -x_prime*x, -x_prime*y, -x_prime]\n","        row2 = [0, 0, 0, x, y, 1, -y_prime*x, -y_prime*y, -y_prime]\n","        A.append(row1)\n","        A.append(row2)\n","    A = np.array(A)\n","    return A\n","\n","def compute_homography(A):\n","    U, S, Vt = np.linalg.svd(A)\n","\n","    h = Vt[-1, :]\n","\n","    H = h.reshape(3, 3)\n","\n","    return H\n","\n","filename = ['r11.jpg', 'r22.jpg']\n","\n","images = []\n","img_path = '/content/drive/My Drive/Colab Notebooks/Assignment3/Sample2/'\n","\n","\n","for i in range(len(filename)):\n","    ## read image and append\n","    images.append(cv2.imread(img_path+filename[i]))\n","    ## resize image to 2500x2500\n","    images[i] = cv2.resize(images[i], (2500, 2500))\n","\n","\n","\n","#Step 2: detect the features and keypoints from SIFT\n","(imageB, imageA) = images\n","(KeypointsA, featuresA) = Detect_Feature_And_KeyPoints(imageA)\n","(KeypointsB, featuresB) = Detect_Feature_And_KeyPoints(imageB)\n","\n","#Step 3: get the valid matched points\n","AllMatches = get_Allpossible_Match(featuresA, featuresB);\n","valid_matches = All_validmatches(AllMatches, lowe_ratio=0.75)\n","\n","#Step 4: Call cv2.findHomography\n","## the goal is to calculate the 3x3 H matrix\n","\n","\n","pointsA = np.float32([KeypointsA[i] for (_,i) in valid_matches])\n","pointsB = np.float32([KeypointsB[i] for (i,_) in valid_matches])\n","\n","(Homograpgy, status) = cv2.findHomography(pointsA, pointsB, cv2.RANSAC,4.0)\n","\n","\n","def alpha_blend(imageA, imageB, Homography, alpha=0.7):\n","    warped_imageB = cv2.warpPerspective(imageB, Homography, (imageA.shape[1], imageA.shape[0]))\n","    maskB = np.any(warped_imageB > 0, axis=-1).astype(np.float32)\n","    maskB = cv2.GaussianBlur(maskB, (21, 21), 0)\n","    maskA = 1.0 - maskB\n","    maskA = np.repeat(maskA[:, :, np.newaxis], 3, axis=2)\n","    maskB = np.repeat(maskB[:, :, np.newaxis], 3, axis=2)\n","    blended = (imageA * maskA * alpha + warped_imageB * maskB * (1 - alpha)).astype(np.uint8)\n","    return blended\n","\n","blended_image = alpha_blend(imageB, imageA, Homograpgy, alpha=0.5)\n","\n","cv2.imwrite(img_path+\"task3.jpg\", blended_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3v09ERsAjgL","executionInfo":{"status":"ok","timestamp":1728759345572,"user_tz":300,"elapsed":4898,"user":{"displayName":"YAN ZHU","userId":"00540976432926720201"}},"outputId":"eaaaa9d6-72c9-417e-fdda-4c1be744f954"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.8.13 ('py3torch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d38809b76120d20a1d3e1d897a4f47c1eaa6798af8e438a196de9dcce5e3189a"}}},"nbformat":4,"nbformat_minor":0}